---
title: "Super Learning"
author: "David Benkeser"
date: "April 19, 2016"
output: html_document
---

## Introduction

In this demonstration, we will illustrate the basic functionality of the `SuperLearner` package. Using simulated data, we illustrate: (1) basic functionality of the package; (2) how to generate custom algorithms; (3) examples of Super Learning for the three examples covered in class; and (4)  how the performance of the Super Learner itself can be evaluated using cross-validation.

## Installing the SuperLearner package
You can execute the following commands to install the packages needed to complete this demo.

```{r install pacakages, message=FALSE}
# install all the necessary pacakges to execute this demo
install.packages(c("SuperLearner","gam","caret","randomForest","arm","RCurl"))

# load the packages
library(c("SuperLearner","gam","caret","randomForest","arm","RCurl"))
```

## Loading data from GitHub
I have made three data sets available on GitHub that will be used in this demo. These can be read directly from GitHub using the following commands:

```{r install pacakages, message=FALSE}
# prediction data set
chspred <- getURL("https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv")

# statin data
statins <- getURL("https://raw.githubusercontent.com/benkeser/sllecture/master/statins.csv")

# hiv vaccine data
hiv <- getURL("https://raw.githubusercontent.com/benkeser/sllecture/master/hiv.csv")
```

## Super Learner with a simple library
We begin by illustrating the "default" functionality of the `SuperLearner` function. Using the `chspred` data, we are interested in predicting myocardial infarcation (`mi`) using the available covariate data. We will consider only a simple library of algorithms: GLM with log-link and Gamma family, GLM with identity-link and Gamma family, and the algorithm proposed by Manning (2001) to adaptively select a GLM. Each GLM only includes a main effects term for each of the covariates. These three algorithms are implemented in the functions `SL.gammaLogGLM`, `SL.gammaIdentityGLM`, and `SL.manningGLM`. Later, we will take a look at how these algorithms are constructed. 

```{r sl1, message=FALSE}
# load the Super Learner package
require(SuperLearner)

# because cross-validation is used, we need to set to the seed to ensure reproducibility
set.seed(1234)

# execute the call to SuperLearner
sl1 <- SuperLearner(
  Y = dat$totalcost, # Y is the outcome variable
  X = dat[,c("female","sofa","race","trt")], # X is a dataframe of predictor variables
  SL.library = c("SL.gammaLogGLM","SL.gammaIdentityGLM","SL.manningGLM") # this is our library specified as a vector of functions
)

sl1
```

By default `SuperLearner` will use ten-fold cross validation and mean squared-error as the loss function. From the output we see that the algorithm `r names(which(sl1$cvRisk==min(sl1$cvRisk)))` had the lowest cross-validated risk and is thus the discrete Super Learner. In fact, the best weighted combination of these three algorithms was judged to give all the weight to the `SL.manningGLM` algorithm and no weight to the other two algorithms. We will discuss why the name of each algorithm has been augmented with the suffix `_All` when we illustrate variable screening functions later in the document. 

Predictions from the discrete and continuous Super Learner on the observed data can now be obtained as follows:
```{r predsl1, message=FALSE, cache=TRUE, warning=FALSE}
# default call to predict
slPred <- predict(sl1)
# slPred is a list with two components
#   pred = continuous SL predictions
#   library.predict = predictions from each algorithm

# store the continuous SL predictions
cslPred <- slPred$pred

# get the discrete SL predictions
dslPred <- slPred$library.predict[,which(sl1$cvRisk==min(sl1$cvRisk))]
```

We can also obtain predictions on a new observation: 
```{r slPredictNew, message=FALSE}
# generate random data for a new observation
newObs <- data.frame(female=1, sofa=8, race=0, trt=1)

# all predictions on newObs
slPredNew <- predict(sl1,newdata=newObs)

# continuous SL prediction on newObs
cslPredNew <- slPredNew$pred

# discrete SL prediction on newObs
dslPredNew <- slPredNew$library.predict[,which(sl1$cvRisk==min(sl1$cvRisk))]
```

We note that if one wishes to access the fitted object for any of the component algorithms (fit using all the data), this can be accessed through the `fitLibrary` component of the `SuperLearner` object. For example, to access the `glm` object from the `SL.gammaLogGLM` algorithm, we can use:
```{r fitlib}
# obtain gamma GLM with log-link fit
glmObject <- sl1$fitLibrary$SL.gammaLogGLM_All$object

# summarize the fit
summary(glmObject)
```

## Evaluating the Super Learner
The `SuperLearner` package comes with an additional function to objectively evaluate the performance of the SuperLearner predictions relative to those from its component methods. This is achieved by adding an additional outer layer of V-fold cross-validation to the procedure. That is the data is split into, for example twenty equally sized pieces and each algorithm is trained on nine-tenths of the data -- including the Super Learner, which itself uses 10-fold cross-validation -- and evaluated on the remaining piece. Each piece of data serves as the evaluation set once and the cross-validated risk of the Super Learner and each component algorithm is computed. 

Continuing our example from the previous section using a simple library, we can use the `CV.SuperLearer` function:
```{r cvSuperLearner, message=FALSE, cache=TRUE, warning=FALSE}
# set seed to ensure reproducibility
set.seed(1234)

# fit cross-validated super learner
cvsl1 <- CV.SuperLearner(
  Y=dat$totalcost, 
  X = dat[,c("female","sofa","race","trt")],
  SL.library = c("SL.gammaLogGLM","SL.gammaIdentityGLM","SL.manningGLM")
)
```

The object itself is not that informative:
```{r cvObj}
cvsl1
```

However, there is a nice plotting function to display the results:
```{r cvPlot, message=FALSE}
# load ggplot2
require(ggplot2)
# plot cross-validated risk
plot(cvsl1)
```

The plot shows the ordered cross-validated risk estimates and 95\% confidence intervals about these estimates for each of the candidate algorithms, in addition to the discrete and continuous Super Learner. In this case, we see that the Manning (2001) algorithm has the lowest cross-validated risk, followed closely by the two Super Learners. However, the confidence intervals are wide and it is difficult at these small sample sizes to determine which method performs best. 

## Writing prediction algorithms for Super Learner
We now discuss how to supply new prediction algorithms to the `SuperLearner` function. First, it is useful to check the algorithms that are included in the `SuperLearner` by default: 
```{r listwrap}
listWrappers()
```
We can also check what is included in the `healthcost` software by default:
```{r listwraphc}
hc.listWrappers()
```

Note that both "prediction" and "screening"" algorithms are shown. We focus first on prediction algorithms. We can view the contents of the `SL.glm` algorithm:
```{r slglm}
SL.glm
```
We note that this function takes as input: `Y`, `X`, `newX`, `family`, `obsWeights`, and other arguments via `...`. For the analysis of health care cost data the `family` option in the call to `SuperLearner` should be set to `gaussian()` (which is the default), so that `Y` is treated as a continuous variable. This option has no bearing on the assumptions made by the Super Learner (i.e., we are not assuming that health costs are normally distributed), but rather, this option is simply passed through to each of the prediction algorithms. This allows one to, for example use a single prediction function when the outcome is both binary and continuous. 

The output of the prediction algorithm is a list with components `pred`, a vector of predictions computed on the `newX` object, and `fit`, which contains anything that is (1) used for predicting new values later; or (2) desired for later access via the `fitLibrary` component of the `SuperLearner` object. Because this `fit` object may be used for prediction later, it is important to specify its class so that an S3 predict method can be used on the object later. Note that such a method is already included for `SL.glm`: 
```{r predslglm}
predict.SL.glm
```

This input/output structure is all that is needed to define a new prediction algorithm for `SuperLearner`. 

As an illustration, we could write a new algorithm specifying a new `glm` algorithm that uses the Gamma error distribution, log link, and a natural spline of degree `d` for any variable with more than `cts.num` unique values, where `d` and `cts.num` are some values chosen by the user: 
```{r newglm, message=FALSE}
require(splines)

SL.gammaLogGLM.ns <- function(Y, X, newX, family, obsWeights,
                              cts.num=4, d=3, ...){
  # check which variables in X have at least cts.num unique values
  cts.x <- apply(X, 2, function(x) (length(unique(x)) > cts.num))
  
  # fit glm with natural spline of degree d for variables 
  # with at least cts.num unique values, and main effects 
  # terms for all other variables
  fit.glm <- glm(as.formula(paste("Y~", paste(paste0("ns(", 
            colnames(X[,cts.x,drop = FALSE]), ",df=", d, 
            ")"), collapse = "+"), "+", paste(colnames(X[, 
            !cts.x, drop = FALSE]), collapse = "+"))),
            data=X, family=Gamma(link='log'), 
            start=c(mean(log(Y)), rep(0, ncol(X)+ (d-1)*sum(cts.x))))
  
  # get predictions
  pred <- predict(fit.glm, newdata=newX, type="response")
  
  # save the fit object
  fit <- list(object=fit.glm)
  
  # because this is simply a different form of glm, 
  # we can use predict.SL.glm to get predictions back, 
  # i.e. no need to write a new predict function
  class(fit) <- "SL.glm"
  
  out <- list(pred=pred, fit=fit)
  return(out)
}
```
We have now defined a new algorithm for use in the SuperLearner. The algorithm first searches through the predictor variables and identifies those with more than `cts.num` unique values. A GLM is then fit using main effects terms for variables with fewer than `cts.num` unique values, and natural splines of degree `d` for variables with more than `cts.num` unique values. 

Note that it is trivial to include existing algorithms with different tuning parameter values. For example, if we wanted to include the above algorithm but using a natrual spline of degree two, we could simply define: 
```{r newglm2}
SL.gammaLogGLM.ns2 <- function(...,d=2){
  SL.gammaLogGLM.ns(...,d=d)
}
```

These new algorithms can now be added to the library we used previously: 
```{r newsl, cache=TRUE, warning=FALSE}
set.seed(12345)

sl2 <- SuperLearner(
  Y = dat$totalcost,
  X = dat[,c("female","sofa","race","trt")], 
  SL.library = c("SL.gammaLogGLM","SL.gammaIdentityGLM","SL.manningGLM","SL.gammaLogGLM.ns","SL.gammaLogGLM.ns2"))

sl2
```

We can double check to make sure that `predict.SL.glm` works for our the new algorithms we defined by attempting to predict on a new observation:
```{r newslpred}
slPredNew2 <- predict(sl2,newdata=newObs)
slPredNew2
```


## Writing screening algorithms for the Super Learner
We now discuss how screening algorithms can be utilized to create larger Super Learner libraries. As the name suggests, these are algorithms that define a screening step prior to the execution of the prediction algorithm. The `SuperLearner` function will apply this screening step in each of the V folds. This combination of screening algorithm and prediction algorithm thus defines a new algorithm. We can look at how screening algorithms are constructed for use with the `SuperLearner` package:
```{r screenalg}
write.screen.template()
```

Screening algorithms take the same input as prediction algorithms, but output a logical vector with `TRUE` indicating that a column of `X` should be used in the prediction step. To illustrate why these functions are useful, in our running example, consider the possibility of an interaction between treatment and SOFA score. If we are unsure of the existence of this interaction, we may wish to include algorithms that both do and do not account for this interaction. To construct a new library that includes algorithms both with and without interactions, we can make use of screening algorithms. 

Let's first set up a new data frame for use with `SuperLearner` that includes a column for the cross product of treatment and SOFA:
```{r newdata}
myX <- data.frame(female=dat$female,
                  sofa=dat$sofa,
                  race=dat$race,
                  trt=dat$trt,
                  sofaInt=dat$trt * dat$sofa)
```

Now let's write a screening algorithm that removes the interaction:
```{r noint}
noInt <- function(X,...){
  return(c(TRUE,TRUE,TRUE,TRUE,FALSE))
}
```

Now we can fit the SuperLearner using the three original algorithms each with and without the interaction. The call to `SuperLearner` is nearly identical; however, we now specify `SL.library` as a list, where each component is a vector of the form `c(predictionAlgorithm,screeningAlgorithm)`. To include the interaction, we specify the `All` screening algorithm that is included in the `SuperLearner` package.
```{r intSL, cache=TRUE, warning=FALSE}
set.seed(1234) 

# Fit the Super Learner
sl3 <- SuperLearner(
  Y=dat$totalcost, 
  X=myX,
  SL.library=list(c("SL.gammaLogGLM","All"),c("SL.gammaLogGLM","noInt"),
                  c("SL.gammaIdentityGLM","All"),c("SL.gammaIdentityGLM","noInt"),
                  c("SL.manningGLM","All"),c("SL.manningGLM","noInt"))
  )

sl3
```

Note that the output for `sl3` lists six algorithms: the three original algorithms each with the interaction (`_All`) and without (`_noInt`). Note that this explains why the output for `sl1` contained the "_All" addendum -- by default `SuperLearner` uses all the `All` screening function to pass through all variables in `X` to the prediction algorithms. 

This flexibility in combining screening and prediction algorithms to generate new algorithms allows one to easily implement a library containing a large number of candidate algorithms.

## Using Super Learner to tune a single method
A corollary of the above is that the Super Learner software can easily be used to implement a single method with many different tuning parameter values. As an example, consider the method developed by Wang (2009) that uses quantile regression and a transformation to estimate the conditional mean health care cost. The method requires three tuning parameters: the number of quantiles to estimate `m` and two parameters that determine the amount of trimming in the transformation of the quantiles to the condtional mean, `b` and `c`. 

We can easily define a new algorithm that uses a single set of values for these parameters, just as we did for `SL.gammaLogGLM.ns2` above: 
```{r wangzhou1, message=FALSE}
SL.wangZhou_m100_b0.01_c0.1 <- function(...,m=100,b=0.01,c=0.1){
  SL.wangZhou(...,m=m,b=b,c=c)
}
```

We can also easily use a loop to define functions over a grid of tuning parameter values:
```{r wangzhou2, message=FALSE}
tuneGrid <-  expand.grid(m = c(50, 100), b=c(0.01, 0.1), c=c(0.1, 0.5))

for(i in seq(nrow(tuneGrid))) { 
  eval(parse(text = paste0("SL.wangZhou_m",tuneGrid[i,1],"_b",tuneGrid[i,2],"_c",tuneGrid[i,3], 
                      "<- function(..., m = ", tuneGrid[i, 1], ", b = ", tuneGrid[i, 2], 
                      ", c = ", tuneGrid[i,3],") { SL.wangZhou(..., m = m, b = b, c = c)}")))
  }
```

We have now created eight new prediction algorithms with each combination of tuning parameters specified in `tuneGrid`. For example, we can look at the algorithm that uses `m=50`, `b=0.01`, and `c=0.1`: 
```{r exwangzhou}
SL.wangZhou_m50_b0.1_c0.1
```
We can collect all of these algorithms by searching through `R` objects with a similar name:
```{r allwangzhou}
# get vector of all objects in R
allObjects <- ls()
# search names of objects for 'SL.wangZhou_m'
wangZhouObjects <- grep("SL.wangZhou_m",allObjects)
# get only objects with 'SL.wangZhou_m' in their name
allWangZhou <- allObjects[wangZhouObjects]
allWangZhou
```

We can now use Super Learner to evaluate the performance of the Wang (2009) method using various tuning parameter values:
```{r wangzhousl, message=FALSE, warning=FALSE, cache=TRUE}
sl4 <- SuperLearner(
  Y=dat$totalcost, 
  X=dat[,c("female","sofa","race","trt")],
  SL.library=allWangZhou  
  )

sl4
```


## Combining Super Learner with the `caret` package
The `caret` package provides a uniform approach to tuning parameter selection for a number of algorithms (for a full list, see http://topepo.github.io/caret/modelList.html). This provides a way to include algorithms in the Super Learner that implicitly use cross-validation. For example, one candidate algorithm in the Super Learner might use a gradient boosted machine with fixed values for tuning parameters, while another candidate algorithm uses a gradient boosted machine with tuning parameters determined adaptively (e.g., through twenty-fold cross-validation). 

The `SuperLearner` package provides an algorithm `SL.caret` to use caret to train an algorithm. The `healthcost` package provides a slight modification of this function `SL.caret1` that fixes an issue dealing with the output from models trained using `caret` when `verbose = TRUE`. The `healthcost` package further supplies several algorithms for using caret with regression trees (`SL.rpart.caret1`), random forests (`SL.rf.caret1`), and gradient boosted machines (`SL.gbm.caret1`). 

As a brief demonstration, we illustrate the implementation of a Super Learner that uses three gradient boosted machine algorithms: `SL.gbm` uses fixed tuning parameters (`gbm.trees=10000` and `interaction.depth=2`); `SL.gbm.caret1` uses twenty-fold cross validation (the default) to select these tuning parameters from a grid of eight possible values; `SL.gbm.caret2` uses ten-fold cross validation to select tuning parameters also from a grid of eight possible values. First we must define `SL.gbm.caret2`:
```{r gbmcaret2, message=FALSE}
SL.gbm.caret2 <- function(...,method="gbm",tuneLength=8, trControl=trainControl(method="cv",number=10,verboseIter=FALSE)){
  SL.caret1(...,method=method,tuneLength=tuneLength,trControl=trControl)
}
```

We can now implement the Super Learner. Note that the run time on this Super Learner will be considerably longer than previous runs due to the additional layers of cross validation.
```{r sl5, message=FALSE, warnings=FALSE, cache=TRUE}
# load caret and gbm package
require(caret)
require(gbm)

set.seed(12345)
# fit super learner using three GBMs
sl5 <- SuperLearner(
  Y=dat$totalcost, 
  X=dat[,c("female","sofa","race","trt")],
  SL.library=c("SL.gbm","SL.gbm.caret1","SL.gbm.caret2")  
  )

sl5
```



